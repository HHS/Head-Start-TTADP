# ----------------- Base Config -----------------

version: 2.1
executors:
  docker-executor:
    docker: # primary container
      - image: cimg/node:20.18.2-browsers
  docker-postgres-executor:
    docker:
      - image: cimg/node:20.18.2-browsers
        environment:
          DATABASE_URL: postgresql://postgres@localhost/ttasmarthub
      - image: cimg/postgres:15.6
        environment:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: secretpass
          POSTGRES_DB: ttasmarthub
  docker-python-executor:
    docker:
      - image: cimg/python:3.9.21
  machine-executor:
    machine:
      image: ubuntu-2204:current

# ----------------- Parameters -----------------

parameters:
  action:
    description: "Desired job to run"
    enum: ["build_test_deploy", "deploy", "cmd", "restore_dbs", "import"]
    default: "build_test_deploy"
    type: enum
  env: 
    description: "(cmd) Target environment"
    default: "dev"
    type: enum
    enum: ["dev-blue", "dev-green", "dev-red", "dev", "sandbox", "staging"]
  cmd_input:
    description: "(cmd) The command to run"
    type: string
    default: ""

# ----------------- Workflows -----------------
workflows:
  build_test_deploy:
    # This is the primary workflow that runs on each push to the GitHub repo
    # Some jobs (such as e2e tests and dynamic security scan) require running on the host machine
    # Therefore these jobs need to be scheduled in sequential order or they will interfere
    when:
      equal: [ build_test_deploy, << pipeline.parameters.action >> ]
    jobs:
      - build_tta_app
      - build_similarity_api
      - watch:
          requires:
            - build_tta_app
      - lint:
          requires:
            - build_tta_app
      - test_similarity_api:
          requires:
            - build_similarity_api
      - test_frontend:
          requires:
            - build_tta_app
      - test_backend:
          requires:
            - build_tta_app
      - test_e2e:
          requires:
            - lint
            - test_frontend
            - test_backend
            - test_similarity_api

      - dynamic_security_scan:
          requires:
            - test_e2e

      # repeat again with different filters for prod/staging and pass the env
      - deploy:
          serial-group: << pipeline.git.branch >>/deploy-lock
          requires:
            - dynamic_security_scan
          filters:
            branches:
              only:
                - dev
                - dev-green
                - sandbox


  run_input_cmd:
    when: 
        equal: [ << pipeline.parameters.action >>, cmd ]
    jobs:
      - run_cmd


  run_import:
    when: 
        equal: [ << pipeline.parameters.action >>, import ]
    jobs:
      - run_cmd:
          command: "node ./build/server/src/tools/importSystemCLI.js download 1"

  backup_restore_db:
    when:
        equal: [ << pipeline.parameters.action >>, restore_dbs ]
    jobs:
      - backup_prod_db
      - process_db:
          requires:
            - backup_prod_db
      - restore_dbs:
           requires:
             - process_db

  daily_task:
    triggers:
      - schedule:
          cron: "0 0 * * *"
          filters:
            branches:
              only:
                - tm/cleanup-circle # normally main
    jobs:
      - run_cmd:
          command: "echo 'hello world'"

# ----------------- Jobs -----------------
jobs:

  run_cmd:
    executor: docker-executor
    resource_class: large
    parameters:
      command:
        type: string
        default: << pipeline.parameters.cmd_input >>
      target_env:
        type: string
        default: << pipeline.parameters.env >>

    steps:
      - cf_cmd:
          the_command: << parameters.command >>
          target_env: << parameters.target_env >>

  watch:
    executor: machine-executor
    steps: 
      - run:
          background: true 
          command: |
            watch 'echo "$(docker ps)"'
      - run:
          background: true 
          command: |
            watch 'echo "$(docker volume ls)"'
      - run:
          command: |
            timeout 10m watch echo 'waiting' && sleep 60s

  backup_prod_db:
    executor: docker-executor
    steps:
      - checkout
      - restore_cache:
          keys:
            - v14-yarn-deps-{{ checksum "combined-yarnlock.txt" }}
            - v14-yarn-deps-
      - run: yarn deps
      - run:
          name: Build backend assets
          command: yarn build
      - run: exit 1
      - cf_backup

  process_db:
    executor: docker-executor
    steps:
      - checkout
      - restore_cache:
          keys:
            - v14-yarn-deps-{{ checksum "combined-yarnlock.txt" }}
            # If checksum is new, restore partial cache
            - v14-yarn-deps-
      - run: yarn deps
      - run:
          name: Build backend assets
          command: yarn build
      - run: exit 1
      - cf_process:
            auth_client_secret: PROD_AUTH_CLIENT_SECRET
            cloudgov_username: CLOUDGOV_PROD_USERNAME
            cloudgov_password: CLOUDGOV_PROD_PASSWORD
            cloudgov_space: CLOUDGOV_PROD_SPACE

  restore_dbs:
    executor: docker-executor
    steps:
      - checkout
      - restore_cache:
          keys:
            - v14-yarn-deps-{{ checksum "combined-yarnlock.txt" }}
            - v14-yarn-deps-
      - run: yarn deps
      - run:
          name: Build backend assets
          command: yarn build
      - run: exit 1
      - cf_restore:
          auth_client_secret: PROD_AUTH_CLIENT_SECRET
          cloudgov_username: CLOUDGOV_PROD_USERNAME
          cloudgov_password: CLOUDGOV_PROD_PASSWORD
          cloudgov_space: CLOUDGOV_PROD_SPACE
          rds_service_name: ttahub-process
          s3_service_name: ttahub-db-backups
          backup_prefix: production

  build_tta_app:
    executor: docker-executor
    resource_class: large
    steps:
      - checkout
      - create_combined_yarnlock
      - restore_cache:
          keys:
            # To manually bust the cache, increment the version e.g. v7-yarn...
            - v15-yarn-deps-{{ checksum "combined-yarnlock.txt" }}
            # If checksum is new, restore partial cache
            - v15-yarn-deps-
      - run: yarn deps
      - save_cache:
          paths:
            - node_modules
            - frontend/node_modules
            - packages/common/node_modules
          key: v15-yarn-deps-{{ checksum "combined-yarnlock.txt" }}
      - run:
          name: Install playwright dependencies
          command: |
            yarn playwright install
      # - run:
      #     name: Check nodejs version compatibility with buildpack
      #     command: |
      #       chmod +x ./bin/check_node_version_compatibility.sh
      #       ./bin/check_node_version_compatibility.sh
      - run: yarn build
      - persist_to_workspace:
          root: .
          paths:
            - .

  build_similarity_api:
    executor: docker-python-executor
    resource_class: large
    steps:
      - checkout
      - create_combined_pipfreeze
      - restore_cache:
          keys:
            # To manually bust the cache, increment the version e.g. v7-pip...
            - v2-pip-deps-{{ checksum "combined-requirements.txt" }}
            # If checksum is new, restore partial cache
            - v2-pip-deps-
      - run:
          name: Install python dependencies
          command: |
            cd similarity_api/src
            python3 -m venv venv
            source venv/bin/activate
            pip install -U pip setuptools wheel
            pip install -U --use-pep517 -r requirements.txt
      - save_cache:
          paths:
            - similarity_api/src/venv
          key: v1-pip-deps-{{ checksum "combined-requirements.txt" }}

      - persist_to_workspace:
          root: .
          paths:
            - similarity_api
            
  lint:
    executor: docker-executor
    resource_class: large
    steps:
      - attach_workspace:
          at: .
      - run:
          name: Lint backend
          command: yarn lint:ci
      - run:
          name: Audit vulnerability of backend node_modules
          command: |
            chmod 744 ./run-yarn-audit.sh
            ./run-yarn-audit.sh;
      - run:
          name: Lint frontend
          command: yarn --cwd frontend lint:ci
      - run:
          name: Audit vulnerability of frontend node_modules
          command: |
            cd frontend
            chmod 744 ./run-yarn-audit.sh
            ./run-yarn-audit.sh;
      - store_artifacts:
          path: reports
          destination: backend-lint.xml
      - store_artifacts:
          path: frontend/reports
          destination: frontend-lint.xml
    
  test_backend:
    executor: docker-postgres-executor
    resource_class: large
    environment:
      SFTP_EXPOSED_PORT: 2222
    steps:
      - attach_workspace:
          at: .
      # - run:
      #     name: Add GitHub to known_hosts
      #     command: ssh-keyscan -H github.com >> ~/.ssh/known_hosts
      - run:
          name: Run migrations ci
          command: yarn db:migrate:ci
      - run:
          name: Run seeders
          command: yarn db:seed:ci
      # everything below this will be executed on the host machine
      # - setup_remote_docker:
      #     version: default
      # - run:
      #     name: Monitor database
      #     background: true
      #     command: |
      #       docker attach  $(docker ps | grep postgres | awk '{print $1}')
      - run:
          name: Test backend
          command: |
            chmod 744 ./bin/test-backend-ci
            ./bin/test-backend-ci
      # Run coverage check script
      - run:
          name: Check coverage for modified lines
          command: |
            ls -la
            pwd
            if [ -n "${CIRCLE_PULL_REQUEST}" ]; then
              chmod +x ./tools/check-coverage.js
              node -r esm ./tools/check-coverage.js \
                --directory-filter=src/,tools/ \
                --fail-on-uncovered=false \
                --output-format=json,html
            else
              echo "Not a PR build. Skipping coverage check."
            fi
          when: always
      - run:
          name: Summarize coverage
          command: |
            chmod +x ./tools/summarize-coverageCLI.js
            node ./tools/summarize-coverageCLI.js \
              ./coverage/coverage-final.json \
              90
          when: always
      - run:
          name: Compress coverage artifacts
          command: tar -cvzf backend-coverage-artifacts.tar coverage/
      - store_artifacts:
          path: coverage/
      - store_artifacts:
          path: backend-coverage-artifacts.tar
      - store_test_results:
          path: reports/
      - store_artifacts:
          path: coverage-artifacts/
          destination: uncovered-lines
    
  test_similarity_api:
    executor: docker-python-executor
    resource_class: large
    steps:
      - attach_workspace:
          at: .
      - run:
          name: Syft SBOM
          environment:
            SYFT_VERSION: v1.5.0
            IMAGE_NAME: ghcr.io/kcirtapfromspace/cloudfoundry_circleci:latest
            OUTPUT_FORMAT: json
            OUTPUT_FILE: reports/syft_sbom.json
          command: |
            mkdir -p reports/
            curl -sSfL https://raw.githubusercontent.com/anchore/syft/main/install.sh | sh -s -- -b . "$SYFT_VERSION"
            ./syft similarity_api/src -vv --scope AllLayers -o "$OUTPUT_FORMAT" > "$OUTPUT_FILE"
            echo "scan results saved in $OUTPUT_FILE"
      - run:
          name: Grype Docker image
          environment:
            GRYPE_VERSION: v0.78.0
            OUTPUT_FORMAT: sarif
            OUTPUT_FILE: reports/grype.json
          command: |
            curl -sSfL https://raw.githubusercontent.com/anchore/grype/main/install.sh | sh -s -- -b . "$GRYPE_VERSION"
            ./grype sbom:reports/syft_sbom.json -v -o "$OUTPUT_FORMAT" > "$OUTPUT_FILE"
            echo "scan results saved in $OUTPUT_FILE"
      - run:
          name: Test similarity
          command: |
            mkdir -p coverage/similarity
            cd similarity_api/src
            source venv/bin/activate
            pip install pytest pytest-cov
            pytest -rpP --cov=similarity --cov=. --junitxml=~/project/reports/junit.xml
            coverage report --show-missing --skip-covered
            coverage html -d ~/project/coverage/similarity --skip-covered
      - store_artifacts:
          path: reports/
    

  test_frontend:
    executor: docker-executor
    resource_class: large
    steps:
      - attach_workspace:
          at: .
      - run:
          name: Audit checksums of color files
          command: |
            chmod 744 ./checkcolorhash.sh
            ./checkcolorhash.sh;
      - run:
          name: Add GitHub to known_hosts
          command: |
            mkdir -p /home/circleci/.ssh
            ssh-keyscan -H github.com >> /home/circleci/.ssh/known_hosts

      - run:
          name: Test frontend
          command: yarn --cwd frontend run test:ci --maxWorkers=50%
      - run:
          name: Check coverage for modified lines
          command: |
            if [ -n "${CIRCLE_PULL_REQUEST}" ]; then
              chmod +x ./tools/check-coverage.js
              node -r esm ./tools/check-coverage.js \
                --coverage-file=../frontend/coverage/coverage-final.json \
                --artifact-dir=../frontend/coverage-artifacts \
                --directory-filter=frontend/ \
                --fail-on-uncovered=false \
                --output-format=json,html
            else
              echo "Not a PR build. Skipping coverage check."
            fi
          when: always
      - store_test_results:
          path: frontend/reports/
      - store_artifacts:
          path: frontend/coverage/
      - store_artifacts:
          path: frontend/coverage-artifacts/
          destination: uncovered-lines

  test_e2e:
    executor: docker-postgres-executor
    steps:
      - attach_workspace:
          at: .
      - setup_remote_docker:
          version: default
      - run:
          name: Start server
          command: |
            BYPASS_AUTH=true
            CURRENT_USER_ID=5
            yarn build
            yarn playwright install
            yarn start:ci
          background: true
      # - run:
      #     name: Build docker file
      #     command: docker build -t tta-testing -f Dockerfile-Testing .
      - run:
          name: Run migrations ci
          command: yarn db:migrate:ci
      - run:
          name: Seed database
          command: yarn db:seed:ci
      - run:
          name: Wait for server to start
          command: ./bin/ping-server 3000
      # - run:
      #     name: Wait for server to start
      #     command: |
      #       docker ps
      #       ./bin/ping-server 9999
      - run:
          command: |
            yarn e2e:ci
      - store_artifacts:
          path: tests/e2e # ci artifacts
      - run: 
          command: |
            yarn e2e:api
      - store_artifacts:
          path: tests/api # api artifacts
      - run:
          command: |
            yarn e2e:utils
      - store_artifacts:
          path: tests/utilsTests # utils artifacts
      - run:
          command: |
            yarn cucumber:ci
      - store_artifacts:
          path:  reports/ # cucumber artifacts


  new_e2e:
    executor: machine-executor
    resource_class: large
    steps:
      - attach_workspace:
          at: .
      # - run:
      #     name: Start server
      #     background: true
      #     command: |
      #       yarn build
      #       yarn playwright install
      #       BYPASS_AUTH=true 
      #       CURRENT_USER_ID=5 
      #       yarn start:ci
      # - run:
      #     name: Run migrations ci
      #     command: yarn db:migrate:ci
      # - run:
      #     name: Seed database
      #     command: yarn db:seed:ci

      # - setup_remote_docker:
      #     version: default
      # - run:
      #     name: Start up local services
      #     background: true
      #     command: |
      #       circleci env subst < ./deployment_config/${cfg_env}_vars.yml > .env
      #       docker compose \
      #         --profile minimal_required_node \
      #         --profile minimal_required_postgres \
      #         --profile minimal_required_redis \
      #         --profile minimal_required_python \
      #         up
      # - run:
      #     name: Start up local services
      #     background: true
      #     command: |
      #       cp .env.example .env
      #       npm install cross-env
      #       docker compose \
      #         --profile minimal_required_postgres \
      #         --profile minimal_required_redis \
      #         --profile minimal_required_python \
      #         --profile minimal_required_node \
      #         up
      # - run:
      #     name: Start up local services
      #     command: |
      #       docker compose -f docker-compose.ci.yml up --build
      # - run:
      #     name: Start up testing server
      #     command: |
      #       cp .env.example .env
      #       docker compose start testingonly db
      #       docker ps
      #- set_env_vars
      - run:
          name: Start up local services
          command: ./bin/prod-style-server
      - run: 
          command: |
            docker compose -f docker-compose.dss.yml run 
      - run:
          name: Build docker file
          command: docker build -t tta-testing -f Dockerfile-Testing .
      - run:
          name: Starting testing server
          background: true
          command: |
            docker run -p 9999:9999 tta-testing yarn start:testingonly
      # - run:
      #     name: Wait for server to start
      #     command: ./bin/ping-server 3000
      - run:
          name: Wait for containers to start
          command: |
            timeout 10m bash -c \
            "until [[ '3' -eq $(docker ps --filter status=running | grep -c 'head-start') ]]; do \
              echo 'waiting 30s' && sleep 30 && docker ps; \
            done"
      - run:
          name: Wait for backend to start
          command: ./bin/ping-server 8080
      - run:
          name: Wait for testing server to start
          command: |
            ./bin/ping-server 9999
      # - run:
      #     name: Wait for backend to start
      #     command: ./bin/ping-server 9999
      - run:
          command: |
            docker run -t tta-testing yarn e2e:ci
      - store_artifacts:
          path: tests/e2e
      - run:
          command: docker run -t tta-testing yarn e2e:api
      - store_artifacts:
          path: tests/api
      - run:
          command: docker run -t tta-testing yarn e2e:utils
      - store_artifacts:
          path: tests/utilsTests
      - run:
          command: docker run -t tta-testing yarn cucumber:ci
      - store_artifacts:
          path:  reports/
    
  dynamic_security_scan:
    executor: machine-executor
    steps:
      - attach_workspace:
          at: .
      # - run:
      #     name: Clean previous reports
      #     command: |
      #       rm -rf reports/server/*
      #       rm -rf reports/similarity_api/*
      - run:
          name: Start up local services
          command: ./bin/prod-style-server
      - run:
          name: Wait for Node.js server to start
          command: ./bin/ping-server 8080
      - run:
          name: Wait for similarity_api to start
          command: ./bin/ping-server 9100 localhost /openapi.json
      - run:
          name: Pull OWASP ZAP docker image
          command: docker pull softwaresecurityproject/zap-stable:latest
      - run:
          name: Run OWASP ZAP scan for Node.js server
          command: ./bin/run-owasp-scan --target http://server:8080 --full
      - run:
          name: Run OWASP ZAP scan for similarity_api
          command: ./bin/run-owasp-scan --target http://similarity_api:8080 --api
      - store_artifacts:
          path: reports

  deploy:
    executor: docker-executor
    resource_class: large
    steps:
      - attach_workspace:
          at: .
      - set_env_vars
      - install_cf_tools
      - run:
          name: Build backend assets
          command: yarn build
      - when:
          condition:
            equal: [ << pipeline.git.branch >>, prod ]
          steps:
            - run:
                name: Create production robots.txt
                command: ./bin/robot-factory
      - run:
          name: Build frontend assets
          command: yarn --cwd frontend run build
      - cf_deploy
      - run:
          name: Run database migrations
          command: |
            set -x
            cf run-task tta-smarthub-${cfg_env} --command "yarn db:migrate:prod" --name migrate
      - notify_new_relic
      - when:
          condition:
            equal: [ << pipeline.git.branch >>, prod ]
          steps:
            - notify_slack_deploy:
                slack_bot_token: $SLACK_BOT_TOKEN
                slack_channel: "acf-ohs-ttahub--contractor-customer-team"

# ----------------- Commands -----------------

commands:

  set_env_vars:
    # set env vars, based on (ci) template in deployment_config
    # these will persist across steps in a job, but not across jobs
    # these values will be available in any subsequent bash env
    parameters:
      target:
        type: string
        default: << pipeline.git.branch >>
    steps:
      - checkout
      - run:
          name: Set env vars
          command: |
            # $real_env maps target environment
            # $cfg_env maps to the env used for config (ie dev-green -> dev)
            real_env=<< parameters.target >>
            cfg_env=<< parameters.target >>
            if [[ $real_env == *"main"* ]]; then real_env="staging"; fi
            if [[ $real_env == *"dev"* ]]; then cfg_env="dev"; fi
            echo "export real_env=${real_env}" >> "$BASH_ENV"
            echo "export cfg_env=${cfg_env}" >> "$BASH_ENV"
            # substitute actual values from circle into ci.vars file
            circleci env subst < ./deployment_config/${cfg_env}_vars_ci.env > ci.vars
            # iterate through ci.vars file and export each line, 
            while read line; do
              if [ -n "${line}" ]; then
                echo "export ${line}">>"$BASH_ENV"
              fi
            done < ci.vars
            cat $BASH_ENV

  install_cf_tools:
    description: "Install Cloud Foundry CLI"
    steps:
      - run:
          name: Install CF tools
          command: |
            # Install Cloud Foundry CLI
            wget -q -O - https://packages.cloudfoundry.org/debian/cli.cloudfoundry.org.key | sudo apt-key add -
            echo "deb https://packages.cloudfoundry.org/debian stable main" | sudo tee /etc/apt/sources.list.d/cloudfoundry-cli.list
            sudo apt-get update
            sudo apt-get install -y cf8-cli
            # Install plugin needed for connect-to-service
            cf install-plugin -f https://github.com/cloud-gov/cf-service-connect/releases/download/v1.1.4/cf-service-connect_linux_amd64
  

  create_combined_yarnlock:
    description: "Concatenate all yarn.json files into single file.
      File is used as checksum source for part of caching key."
    parameters:
      filename:
        type: string
        default: "combined-yarnlock.txt"
    steps:
      - run:
          name: Combine package-lock.json files to single file
          command: cat yarn.lock frontend/yarn.lock packages/common/yarn.lock > << parameters.filename >>

  create_combined_pipfreeze:
    description: "Concatenate all requirements.txt files into a single file. File is used as checksum source for part of caching key."
    parameters:
      filename:
        type: string
        default: "combined-requirements.txt"
    steps:
      - run:
          name: Combine requirements.txt files to single file
          command: cat similarity_api/src/requirements.txt > << parameters.filename >>
 

  sparse_checkout:
    description: "Checkout sparse directories from a specific branch."
    parameters:
      directories:
        type: string
        description: "Comma-separated list of directories to checkout sparsely"
      branch:
        type: string
        description: "Branch to checkout"
    steps:
      - run:
          name: Install Git
          command: |
            sudo apt-get update && sudo apt-get install -y git
      - run:
          name: Clone Repository
          command: |
            git clone --no-checkout --filter=blob:none << pipeline.project.git_url >>.git .
      - run:
          name: Sparse Checkout
          environment:
            DIRECTORIES: "<< parameters.directories >>"
          command: |
            git config core.sparseCheckout true
            echo $DIRECTORIES | tr ',' '\n' | while read dir; do
              echo "$dir" | tee -a .git/info/sparse-checkout
            done

  notify_new_relic:
    description: "Notify new relic of a deploy"
    steps:
      - run:
          name: Notify New Relic
          command: |
            source ci.vars
            curl -X POST "https://api.newrelic.com/v2/applications/${new_relic_app_id}/deployments.json" \
            -H "X-Api-Key: $NEW_RELIC_REST_API_KEY" -i \
            -H "Content-Type: application/json" \
            -d \
            "{
              \"deployment\": {
                \"revision\": \"<< pipeline.git.revision >>\",
                \"description\": \"${real_env} Successfully Deployed\"
              }
            }"

  cf_deploy:
    description: "Login to cloud foundry space with service account credentials
      and push application using deployment configuration file."  
    steps:
      - run:
          name: Login with service account
          command: |
            cf login -a ${cg_api} \
              -u ${cg_username} \
              -p ${cg_password} \
              -o ${cg_org} \
              -s ${cg_space}
      - run:
          name: Push application
          command: |
            circleci env subst < ./deployment_config/${cfg_env}_vars.yml > app.vars
            set -x
            echo "Deploying app@branch:[$CIRCLE_BRANCH] to [${real_env}]"
            cf push \
              --vars-file app.vars \
              --var BUILD_BRANCH=${CIRCLE_BRANCH} \
              --var BUILD_COMMIT=${CIRCLE_SHA1} \
              --var BUILD_NUMBER=<< pipeline.number >> \
              --var NEW_RELIC_LICENSE_KEY="${NEW_RELIC_LICENSE_KEY}" \
              --var SMTP_IGNORE_TLS="${SMTP_IGNORE_TLS}" \
              --var BUILD_TIMESTAMP="$(date +"%Y-%m-%d %H:%M:%S")"

  notify_slack:
    description: "Notify Slack with message"
    parameters:
      slack_bot_token:
        description: "Slack bot token"
        type: string
      slack_channel:
        description: "Slack channel name to post the message to"
        type: string
      message_text:
        description: "Message text to post to Slack"
        type: string
        default: ""
      message_text_file:
        description: "message text_file"
        type: string
        default: ""
    steps:
      - run:
          name: Notify Slack
          command: |
            set -x

            # Evaluate message_text_script if provided
            if [ -n "<< parameters.message_text_file >>" ]; then
              MESSAGE_TEXT=$(cat "<< parameters.message_text_file >>")
            else
              MESSAGE_TEXT="<< parameters.message_text >>"
            fi

            echo $MESSAGE_TEXT

            # Ensure all parameters are provided
            if [ -z "<< parameters.slack_bot_token >>" ] || [ -z "<< parameters.slack_channel >>" ] || [ -z "$MESSAGE_TEXT" ]; then
              echo "Missing required parameters. Notification will not be sent."
              exit 1
            fi

            response=$(curl -s -X POST \
              -H "Authorization: Bearer << parameters.slack_bot_token >>" \
              -H 'Content-type: application/json;charset=utf-8' \
              --data "{
                \"channel\": \"<< parameters.slack_channel >>\",
                \"text\": \"$MESSAGE_TEXT\"
              }" \
              https://slack.com/api/chat.postMessage)

            ok=$(echo $response | jq -r '.ok')
            error=$(echo $response | jq -r '.error')

            if [ "$ok" != "true" ]; then
              echo "Slack notification failed: $error"
            else
              echo "Slack notification sent successfully"
            fi

  notify_slack_deploy:
    parameters:
      slack_bot_token:
        description: "Slack bot token"
        type: string
      slack_channel:
        description: "Slack channel name to post the message to"
        type: string
    steps:
      - checkout
      - run:
          name: Generate Message
          command: |
            source ci.vars
            env_name="$real_env"
            if [ -n "${CIRCLE_PULL_REQUEST}" ]; then
                PR_NUMBER=${CIRCLE_PULL_REQUEST##*/}

                PR_TITLE=$(curl -s "${CIRCLE_PULL_REQUEST}" | sed -e :a -e "N; s/\n/ /g; ta" | grep -oP "<bdi class=\"js-issue-title markdown-title\">[^<]+</bdi>" | sed -re "s~<[^>]+>~~g" | sed -e 's/"/\\"/g')

                if [ ! -z "${PR_TITLE}" ]; then
                    JIRA_URLS=$(curl -s "${CIRCLE_PULL_REQUEST}" | sed -e :a -e "N; s/\n/ /g; ta" | grep -oP "Issue[(]s[)]</h2>.*Checklists</h2>" | grep -oP "\"https[^\"]+\"" | sed -e "s~\"~~g" | grep -o "https://jira.acf.gov/browse/[A-Z0-9-]*")

                    MESSAGE_TEXT=":rocket: Deployment of PR <${CIRCLE_PULL_REQUEST}|${PR_NUMBER}> (${PR_TITLE}) to <${ENV_URL}|${env_name}> was successful!"
                    if [ -n "${JIRA_URLS}" ]; then
                        MESSAGE_TEXT="${MESSAGE_TEXT}\nJIRA URLs in the PR:\n${JIRA_URLS}"
                    fi
                else
                    MESSAGE_TEXT=":rocket: Deployment of PR <${CIRCLE_PULL_REQUEST}|${PR_NUMBER}> to <${ENV_URL}|${env_name}> was successful!"
                fi
            else
                COMMIT_MESSAGE=$(git log -1 --pretty=%B)
                if echo "$COMMIT_MESSAGE" | grep -q "Merge pull request #"; then
                  PR_NUMBER=$(git log -1 --pretty=%B | grep -oP '(?<=Merge pull request #)\d+')
                  PR_LINK="https://github.com/HHS/Head-Start-TTADP/pull/${PR_NUMBER}"
                  MESSAGE_TEXT=":rocket: Deployment of PR <${PR_LINK}|${PR_NUMBER}> to <${ENV_URL}|${env_name}> was successful!"
                  if [ ! -z "${JIRA_URLS}" ]; then
                      MESSAGE_TEXT="${MESSAGE_TEXT}\nJIRA URLs in the PR:\n${JIRA_URLS}"
                  fi
                else
                    MESSAGE_TEXT=":rocket: Deployment to <${ENV_URL}|${env_name}> was successful!"
                fi
            fi
            echo -e "${MESSAGE_TEXT}" > /tmp/message_file

      - notify_slack:
          slack_bot_token: << parameters.slack_bot_token >>
          slack_channel: << parameters.slack_channel >>
          message_text_file: "/tmp/message_file"

  cf_cmd:
    description: "Login to Cloud Foundry space, run automation task, and send notification"
    parameters:
      the_command:
        description: "Command to run"
        type: string
      target_env:
        description: "Desired env to run cmd in"
        type: string
    steps:
      - checkout
      - install_cf_tools
      - set_env_vars:
          target: << parameters.target_env >>
      - run:
          name: Login with service account
          command: |
              cf login -a ${cg_api} \
              -u ${cg_username} \
              -p ${cg_password} \
              -o ${cg_org} \
              -s ${cg_space}

      - run:
          name: "Run Task: << parameters.the_command >>"
          command: |
            set -x
            TASK_NAME="ci-task-${CIRCLE_BUILD_NUM}"
            circleci env subst < ./deployment_config/${cfg_env}_vars.yml > app.vars

            cf logs tta-smarthub-<< parameters.target_env >> | grep ${TASK_NAME} & 
            cf run-task \
              tta-smarthub-<< parameters.target_env >> \
              --command "<< parameters.the_command >>" \
              --name ${TASK_NAME} \
              -m 2GB \
              -k 2GB \
              --wait
              
      - run:
          name: Logout of service account
          command: |
            # Signal the log monitoring to stop
            CONTROL_FILE="/tmp/stop_tail"
            touch $CONTROL_FILE

            # Wait for the log monitoring process to terminate
            sleep 5

            # Logout from Cloud Foundry
            cf logout


  cf_backup:
    description: "Backup database to S3"
    steps:
      - cf_automation_task:
          auth_client_secret: ${AUTH_CLIENT_SECRET}
          cloudgov_username: ${cg_username}
          cloudgov_password: ${cg_password}
          cloudgov_space: ${cg_space}
          task_name: "backup"
          task_command: "cd /home/vcap/app/db-backup/scripts; bash ./db_backup.sh"
          task_args: '["<< parameters.backup_prefix >>", "<< parameters.rds_service_name >>", "<< parameters.s3_service_name >>"]'
          config: "<< parameters.backup_prefix >>-backup"
          success_message: ':download::database: "<< parameters.backup_prefix >>" backup'

  cf_restore:
    description: "Restore backup database from S3"
    parameters:
      auth_client_secret: { type: env_var_name }
      cloudgov_username: { type: env_var_name }
      cloudgov_password: { type: env_var_name }
      cloudgov_space: { type: env_var_name }
      rds_service_name: { type: string }
      s3_service_name: { type: string }
      backup_prefix: { type: string }
    steps:
      - run:
          name: Validate Parameters
          command: |
            if [ "<< parameters.rds_service_name >>" = "ttahub-prod" ]; then
              echo "Error: rds_service_name cannot be 'ttahub-prod'"
              exit 1
            fi
      - cf_automation_task:
          auth_client_secret: << parameters.auth_client_secret >>
          cloudgov_username: << parameters.cloudgov_username >>
          cloudgov_password: << parameters.cloudgov_password >>
          cloudgov_space: << parameters.cloudgov_space >>
          task_name: "restore"
          task_command: "cd /home/vcap/app/db-backup/scripts; bash ./db_restore.sh"
          task_args: '["<< parameters.backup_prefix >>", "<< parameters.rds_service_name >>", "<< parameters.s3_service_name >>"]'
          config: "<< parameters.backup_prefix >>-restore"
          success_message: ':database: "<< parameters.backup_prefix >>" Restored to "<< parameters.rds_service_name >>"'
          timeout: "900"
  cf_process:
    description: "Process database from S3"
    parameters:
      auth_client_secret: { type: env_var_name }
      cloudgov_username: { type: env_var_name }
      cloudgov_password: { type: env_var_name }
      cloudgov_space: { type: env_var_name }
    steps:
      - cf_automation_task:
          auth_client_secret: << parameters.auth_client_secret >>
          cloudgov_username: << parameters.cloudgov_username >>
          cloudgov_password: << parameters.cloudgov_password >>
          cloudgov_space: << parameters.cloudgov_space >>
          task_name: "process"
          task_command: "cd /home/vcap/app/automation/nodejs/scripts; bash ./run.sh"
          task_args: '["/home/vcap/app/build/server/src/tools/processDataCLI.js"]'
          config: "process"
          success_message: ':database: Restored data processed'
          directory: "./"
          timeout: "3000"

  cf_retention:
    description: "Delete Backup from S3 based on retention"
    parameters:
      auth_client_secret: { type: env_var_name }
      cloudgov_username: { type: env_var_name }
      cloudgov_password: { type: env_var_name }
      cloudgov_space: { type: env_var_name }
      s3_service_name: { type: string }
      backup_prefix: { type: string }
    steps:
      - cf_automation_task:
          auth_client_secret: << parameters.auth_client_secret >>
          cloudgov_username: << parameters.cloudgov_username >>
          cloudgov_password: << parameters.cloudgov_password >>
          cloudgov_space: << parameters.cloudgov_space >>
          task_name: "retention"
          task_command: "cd /home/vcap/app/db-backup/scripts; bash ./db_retention.sh"
          task_args: '["<< parameters.backup_prefix >>", "<< parameters.s3_service_name >>"]'
          config: "<< parameters.backup_prefix >>-backup"
          success_message: ':database: "<< parameters.backup_prefix >>" retention processed'


  cf_automation_task:
    description: "Login to Cloud Foundry space, run automation task, and send notification"
    parameters:
      auth_client_secret:
        description: "Name of CircleCi project environment variable that holds authentication client secret"
        type: env_var_name
      cloudgov_username:
        description: "Name of CircleCi project environment variable that holds deployer username for Cloud Foundry space"
        type: env_var_name
      cloudgov_password:
        description: "Name of CircleCi project environment variable that holds deployer password for Cloud Foundry space"
        type: env_var_name
      cloudgov_space:
        description: "Name of CircleCi project environment variable that holds name of Cloud Foundry space to target for application deployment"
        type: env_var_name
      task_name:
        description: "Name of the automation task to run"
        type: string
      task_command:
        description: "Command to run for the automation task"
        type: string
      task_args:
        description: "Arguments for the automation task"
        type: string
      config:
        description: "Config prefix for the automation task"
        type: string
      success_message:
        description: "Success message for Slack notification"
        type: string
      timeout:
        description: "Max duration allowed for task"
        type: string
        default: "300"
      directory:
        description: 'directory to root to push'
        type: string
        default: "./automation"
    steps:
        - run:
            command: |
              echo "Running "<< parameters.task_command >>"
      # - run:
      #     name: Install Dependencies
      #     command: |
      #       set -e
      #       set -u
      #       set -o pipefail
      #       set -o noglob
      #       set -o noclobber

      #       # update
      #       sudo apt-get update
      #       # Install uuid-runtime to have access to uuidgen
      #       # Install pv wget
      #       sudo apt-get install -y pv uuid-runtime wget coreutils jq

      #       # Install Cloud Foundry CLI
      #       wget -q -O - https://packages.cloudfoundry.org/debian/cli.cloudfoundry.org.key | sudo apt-key add -
      #       echo "deb https://packages.cloudfoundry.org/debian stable main" | sudo tee /etc/apt/sources.list.d/cloudfoundry-cli.list
      #       sudo apt-get update
      #       sudo apt-get install -y cf8-cli
      #       # Install plugin needed for connect-to-service
      #       cf install-plugin -f https://github.com/cloud-gov/cf-service-connect/releases/download/v1.1.3/cf-service-connect_linux_amd64

      #       # The line you want to ensure exists in the /etc/hosts file
      #       line="127.0.0.1        localhost"

      #       # Check if the line already exists
      #       if ! grep -qF "$line" /etc/hosts; then
      #           # If the line does not exist, append it
      #           echo "$line" | sudo tee -a /etc/hosts > /dev/null
      #           echo "Line added to /etc/hosts"
      #       else
      #           echo "Line already exists in /etc/hosts"
      #       fi

      #       # cleanup
      #       sudo rm -rf /var/lib/apt/lists/*
      # - run:
      #     name: Login with service account
      #     command: |
      #       cf login -a << pipeline.parameters.cg_api >> \
      #         -u ${<< parameters.cloudgov_username >>} \
      #         -p ${<< parameters.cloudgov_password >>} \
      #         -o << pipeline.parameters.cg_org >> \
      #         -s ${<< parameters.cloudgov_space >>}
      # - run:
      #     name: Acquire Lock
      #     command: |
      #       chmod +x ./automation/ci/scripts/*-lock.sh
      #       ./automation/ci/scripts/acquire-lock.sh \
      #         "tta-automation" \
      #         "<< pipeline.git.branch >>" \
      #         "<< pipeline.number >>" \
      #         "$CIRCLE_JOB"
      # - run:
      #     name: Start Log Monitoring
      #     command: |
      #       #!/bin/bash

      #       CONTROL_FILE="/tmp/stop_tail"
      #       rm -f $CONTROL_FILE

      #       # Function to start tailing logs
      #       start_log_tailing() {
      #           echo "Starting cf logs for tta-automation..."
      #           cf logs tta-automation &
      #           TAIL_PID=$!
      #       }

      #       # Start tailing logs for the first time
      #       start_log_tailing

      #       # Monitor the cf logs process
      #       while [ ! -f $CONTROL_FILE ]; do
      #           # Check if the cf logs process is still running
      #           if ! kill -0 $TAIL_PID 2>/dev/null; then
      #               echo "cf logs command has stopped unexpectedly. Restarting..."
      #               start_log_tailing
      #           fi
      #           sleep 1
      #       done

      #       # Kill the cf logs command
      #       kill -9 $TAIL_PID
      #       echo "cf logs command for tta-automation has been terminated."
      #     background: true
      # - run:
      #     name: cf_lambda - script to trigger task
      #     command: |
      #       set -x
      #       json_data=$(jq -n \
      #         --arg directory "<< parameters.directory >>" \
      #         --arg config "<< parameters.config >>" \
      #         --arg task_name "<< parameters.task_name >>" \
      #         --arg command "<< parameters.task_command >>" \
      #         --arg timeout_active_tasks "<< parameters.timeout >>" \
      #         --arg timeout_ensure_app_stopped "<< parameters.timeout >>" \
      #         --argjson args '<< parameters.task_args >>' \
      #         '{
      #           directory: $directory,
      #           config: $config,
      #           task_name: $task_name,
      #           command: $command,
      #           timeout_active_tasks: $timeout_active_tasks,
      #           timeout_ensure_app_stopped: $timeout_ensure_app_stopped,
      #           args: $args
      #         }')

      #       # Set execute permission
      #       find ./automation -name "*.sh" -exec chmod +x {} \;

      #       ./automation/ci/scripts/cf_lambda.sh "$json_data"
      # - run:
      #     name: Generate Message
      #     command: |
      #       if [ ! -z "$CIRCLE_PULL_REQUEST" ]; then
      #         PR_NUMBER=${CIRCLE_PULL_REQUEST##*/}
      #         echo "<< parameters.success_message >> before PR <$CIRCLE_PULL_REQUEST|$PR_NUMBER> successful!" > /tmp/message_file
      #       else
      #         echo "<< parameters.success_message >> successful!" > /tmp/message_file
      #       fi
      # - notify_slack:
      #     slack_bot_token: $SLACK_BOT_TOKEN
      #     slack_channel: "acf-head-start-eng"
      #     message_text_file: "/tmp/message_file"
      # - run:
      #     name: Release Lock
      #     command: |
      #       chmod +x ./automation/ci/scripts/*-lock.sh
      #       ./automation/ci/scripts/release-lock.sh \
      #         "tta-automation" \
      #         "<< pipeline.git.branch >>" \
      #         "<< pipeline.number >>" \
      #         "$CIRCLE_JOB"
      # - run:
      #     name: Logout of service account
      #     command: |
      #       # Signal the log monitoring to stop
      #       CONTROL_FILE="/tmp/stop_tail"
      #       touch $CONTROL_FILE

      #       # Wait for the log monitoring process to terminate
      #       sleep 5

      #       # Logout from Cloud Foundry
      #       cf logout

