# ----------------- Base Config -----------------

version: 2.1
executors:
  docker-executor:
    docker:
    - image: cimg/node:20.19.3-browsers
  docker-postgres-executor:
    docker:
    - image: cimg/node:20.19.3-browsers
      environment:
        DATABASE_URL: postgresql://postgres@localhost/ttasmarthub
        REDIS_HOST: localhost
        REDIS_PASS: secretpass
    - image: cimg/postgres:15.12
      environment:
        POSTGRES_USER: postgres
        POSTGRES_PASSWORD: secretpass
        POSTGRES_DB: ttasmarthub
    - image: cimg/redis:6.2.17
      environment:
        REDIS_PASSWORD: secretpass
  docker-python-executor:
    docker:
    - image: cimg/python:3.9.21
  docker-base:
    docker:
    - image: cimg/base:2021.04
  machine-executor:
    machine:
      image: ubuntu-2204:current

# ----------------- Parameters -----------------

parameters:
  action:
    description: "Choose the workflow to run"
    type: enum
    enum: [ build_test_deploy, deploy_only, import_data, restore_db, backup_prod, clear_cache ]
    default: build_test_deploy
  target_env:
    description: "Environment to target"
    type: enum
    enum: [ '-', dev-blue, dev-green, dev-red, dev-gold, dev-pink, staging ]
    default: '-'

# ----------------- Workflows -----------------

workflows:
  build_test_deploy:
    # This is the primary workflow that runs on each push to the GitHub repo
    # It will build the app, run all tests, then deploy if the branch matches
    # autodeploy: main->staging, production->prod
    when: pipeline.parameters.action == "build_test_deploy"
    max_auto_reruns: 3
    jobs:
    - build_and_lint
    - checkpoint:
        name: build_done
        requires:
        - build_and_lint
    - test_frontend:
        requires:
        - build_done
    - test_backend:
        requires:
        - build_done
    - test_e2e_app:
        requires:
        - build_done
    - test_e2e_api:
        requires:
        - build_done
    - test_e2e_utils:
        requires:
        - build_done
    - test_cucumber:
        requires:
        - build_done
    - dynamic_security_scan:
        requires:
        - build_done
    - checkpoint:
        name: tests_done
        requires:
        - test_frontend
        - test_backend
        - test_e2e_app
        - test_e2e_api
        - test_e2e_utils
        - test_cucumber
        - dynamic_security_scan
    - deploy_job:
        name: autodeploy_staging
        serial-group: deploy-lock/staging
        target_env: "staging"
        requires:
        - tests_done
        filters:
          branches:
            only:
            - main
    - deploy_job:
        name: autodeploy_prod
        serial-group: deploy-lock/prod
        target_env: "prod"
        requires:
        - tests_done
        filters:
          branches:
            only:
            - production

  deploy_only:
    # job to be triggered manually, will build the app and deploy to target env
    when: pipeline.parameters.action == "deploy_only" and pipeline.trigger_source == "api"
    jobs:
    - build_and_lint
    - deploy_job:
        name: deploy (<< pipeline.parameters.target_env >>)
        serial-group: << pipeline.parameters.target_env >>/deploy-lock
        target_env: "<< pipeline.parameters.target_env >>"
        requires:
        - build_and_lint

  import_data_cron:
    # scheduled job to download and process monitoring data
    triggers:
    - schedule:
        cron: "0 13 * * *" # 1PM UTC = 9AM EST
        filters:
          branches:
            only:
            - production
    jobs:
    - run_import_job:
        target_env: "prod"
        slack_channel: acf-ohs-ttahub--contractor-customer-team

  import_data_manual:
    # for manual testing of the data import workflow
    when: pipeline.parameters.action == "import_data" and pipeline.trigger_source == "api"
    jobs:
    - run_import_job:
        target_env: "<< pipeline.parameters.target_env >>"

  restore_db_cron:
    # scheduled job to ensure lower envs have a recent copy of the database
    # backup prod db to snapshot
    # restore prod db to temp db
    # process (anonymize) the data in temp db
    # backup temp db to snapshot
    # restore temp snapshot to lower env dbs
    # run migrations
    max_auto_reruns: 3
    triggers:
    - schedule:
        cron: "0 4 * * *" # 4AM UTC = 12AM EST
        filters:
          branches:
            only:
            - main
    jobs:
    - backup_prod_db:
        serial-group: "tta-automation-lock"
    - restore_prod_to_temp:
        serial-group: "tta-automation-lock"
        requires:
        - backup_prod_db
    - process_temp_db:
        serial-group: "tta-automation-lock"
        requires:
        - restore_prod_to_temp
    - backup_temp_db:
        serial-group: "tta-automation-lock"
        requires:
        - process_temp_db
    - restore_db_job:
        name: restore (dev-green)
        serial-group: "tta-automation-lock"
        target_env: "dev-green"
        requires:
        - backup_temp_db
    - restore_db_job:
        name: restore (dev-blue)
        serial-group: "tta-automation-lock"
        target_env: "dev-blue"
        requires:
        - backup_temp_db
    - restore_db_job:
        name: restore (dev-red)
        serial-group: "tta-automation-lock"
        target_env: "dev-red"
        requires:
        - backup_temp_db
    - restore_db_job:
        name: restore (dev-gold)
        serial-group: "tta-automation-lock"
        target_env: "dev-gold"
        requires:
        - backup_temp_db
    - restore_db_job:
        name: restore (dev-pink)
        serial-group: "tta-automation-lock"
        target_env: "dev-pink"
        requires:
        - backup_temp_db
    - restore_db_job:
        name: restore (staging)
        serial-group: "tta-automation-lock"
        target_env: "staging"
        requires:
        - backup_temp_db

  backup_prod_manual:
    # backup prod db, process(anonymize) it, then backup the processed db
    when: pipeline.parameters.action == "backup_prod" and pipeline.trigger_source == "api"
    jobs:
    - backup_prod_db:
        serial-group: "tta-automation-lock"
    - restore_prod_to_temp:
        serial-group: "tta-automation-lock"
        requires:
        - backup_prod_db
    - process_temp_db:
        serial-group: "tta-automation-lock"
        requires:
        - restore_prod_to_temp
    - backup_temp_db:
        serial-group: "tta-automation-lock"
        requires:
        - process_temp_db

  restore_db_manual:
    # restore the anonymized db snapshot to a lower env db and run migrations
    # uses the last production backup, does not interact with prod or modify snapshots
    when: pipeline.parameters.action == "restore_db" and pipeline.trigger_source == "api"
    jobs:
    - restore_db_job:
        serial-group: tta-automation-lock
        target_env: "<< pipeline.parameters.target_env >>"

  clear_build_cache:
    when: pipeline.parameters.action == "clear_cache" and pipeline.trigger_source == "api"
    jobs:
    - clear_cache_job:
        target_env: << pipeline.parameters.target_env >> 

  clear_buildcache_cron:
    # the build cache grows over time, causing deploys to fail.  this job will clear it weekly
    # see https://docs.cloud.gov/knowledge-base/2024/12/09/apt-buildpack-cache-issue/
    triggers:
    - schedule:
        cron: "0 0 * * 0" # midnight Sunday
        filters:
          branches:
            only:
            - main
    jobs:
    - clear_cache_job:
        target_env: "tta-smarthub-prod" 
    - clear_cache_job:
        target_env: "tta-smarthub-staging"
    - clear_cache_job:
        target_env: "tta-automation"
    - clear_cache_job:
        target_env: "tta-smarthub-dev-blue" 
    - clear_cache_job:
        target_env: "tta-smarthub-dev-green" 
    - clear_cache_job:
        target_env: "tta-smarthub-dev-red" 
    - clear_cache_job:
        target_env: "tta-smarthub-dev-gold" 
    - clear_cache_job:
        target_env: "tta-smarthub-dev-pink"
        

# ----------------- Jobs -----------------

jobs:
  build_and_lint:
    executor: docker-executor
    resource_class: large
    steps:
    - checkout
    - create_combined_yarnlock
    - restore_cache:
        keys:
        # To manually bust the cache, increment the version e.g. v7-yarn...
        - v16-yarn-deps-{{ checksum "combined-yarnlock.txt" }}
        # If checksum is new, restore partial cache
        - v16-yarn-deps-
    - run: yarn deps
    - save_cache:
        paths:
        - node_modules
        - frontend/node_modules
        - packages/common/node_modules
        key: v16-yarn-deps-{{ checksum "combined-yarnlock.txt" }}
    - run:
        name: Ensure reports directory exists
        command: mkdir reports
    - run: yarn build
    - run:
        name: Lint backend
        command: yarn lint:ci
    - run:
        name: Audit vulnerability of backend node_modules
        command: |
          chmod 744 ./tools/run-yarn-audit.js
          ./tools/run-yarn-audit.js;
    - run:
        name: Lint frontend
        command: yarn --cwd frontend lint:ci
    - run:
        name: Audit vulnerability of frontend node_modules
        command: |
          cd frontend
          chmod 744 ../tools/run-yarn-audit.js
          ../tools/run-yarn-audit.js;
    - store_artifacts:
        path: reports
        destination: backend-lint.xml
    - store_artifacts:
        path: frontend/reports
        destination: frontend-lint.xml
    - persist_to_workspace:
        root: .
        paths:
        - .

  test_backend:
    executor: docker-postgres-executor
    resource_class: large
    environment:
      SFTP_EXPOSED_PORT: 2222
    steps:
    - attach_workspace:
        at: .
    - run:
        name: Add GitHub to known_hosts
        command: |
          mkdir -p ~/.ssh/
          touch ~/.ssh/known_hosts
          ssh-keyscan -H github.com >> ~/.ssh/known_hosts
    - run:
        name: Run migrations ci
        command: yarn db:migrate:ci
    - run:
        name: Run seeders
        command: yarn db:seed:ci
    - run:
        name: Test backend
        command: |
          chmod 744 ./bin/test-backend-ci
          ./bin/test-backend-ci
    - run:
        name: Merge coverage & generate report
        when: always
        command: |
          temp_dir="coverage-temp"
          report_dir="coverage-report"
          mkdir -p ${temp_dir}

          find . -name "coverage-final.json" -print0 | while IFS= read -r -d $'\0' file; do
            relative_path="${file#./}"
            new_name="${relative_path//\//-}"
            new_path="${temp_dir}/${new_name}"
            cp "$file" "${new_path}"
          done
          npx nyc merge ${temp_dir} ${temp_dir}/merged-coverage.json
          npx nyc report --temp-dir ${temp_dir} --report-dir ${report_dir} --reporter=html --reporter=json-summary
          echo "Coverage report: https://output.circle-artifacts.com/output/job/${CIRCLE_WORKFLOW_JOB_ID}/artifacts/${CIRCLE_NODE_INDEX}/coverage-report/index.html"
    - run:
        name: Check coverage for modified lines
        when: always
        command: |
          if [ -n "${CIRCLE_PULL_REQUEST}" ]; then
            chmod +x ./tools/check-coverage.js
            node -r esm ./tools/check-coverage.js \
              --directory-filter=src/,tools/ \
              --fail-on-uncovered=false \
              --output-format=json,html
          else
            echo "Not a PR build. Skipping coverage check."
          fi
    - run:
        name: Summarize coverage
        when: always
        command: |
          chmod +x ./tools/summarize-coverageCLI.js
          node ./tools/summarize-coverageCLI.js \
            ./coverage/coverage-final.json \
            90
    - run:
        name: Compress coverage artifacts
        command: zip backend-coverage-artifacts.zip coverage/
        when: always
    - store_artifacts:
        path: backend-coverage-artifacts.zip
    - store_artifacts:
        path: coverage-report/
    - store_artifacts:
        path: coverage-artifacts/
        destination: uncovered-lines
    - store_test_results:
        path: reports/

  test_frontend:
    executor: docker-executor
    resource_class: large
    steps:
    - attach_workspace:
        at: .
    - run:
        name: Audit checksums of color files
        command: |
          chmod 744 ./frontend/checkcolorhash.sh
          cd frontend && ./checkcolorhash.sh;
    - run:
        name: Add GitHub to known_hosts
        command: |
          mkdir -p /home/circleci/.ssh
          ssh-keyscan -H github.com >> /home/circleci/.ssh/known_hosts
    - run:
        name: Test frontend
        command: yarn --cwd frontend run test:ci --maxWorkers=50%
    - run:
        name: Check coverage for modified lines
        command: |
          if [ -n "${CIRCLE_PULL_REQUEST}" ]; then
            chmod +x ./tools/check-coverage.js
            node -r esm ./tools/check-coverage.js \
              --coverage-file=../frontend/coverage/coverage-final.json \
              --artifact-dir=../frontend/coverage-artifacts \
              --directory-filter=frontend/ \
              --fail-on-uncovered=false \
              --output-format=json,html
          else
            echo "Not a PR build. Skipping coverage check."
          fi
        when: always
    - store_test_results:
        path: frontend/reports/
    - store_artifacts:
        path: frontend/coverage/
    - store_artifacts:
        path: frontend/coverage-artifacts/
        destination: uncovered-lines

  test_e2e_app:
    executor: docker-postgres-executor
    resource_class: large
    steps:
    - run_e2e_test:
        cmd: yarn e2e
        artifact_path: tests/e2e

  test_e2e_api:
    executor: docker-postgres-executor
    steps:
    - run_e2e_test:
        cmd: yarn e2e:api
        artifact_path: tests/api

  test_e2e_utils:
    executor: docker-postgres-executor
    steps:
    - run_e2e_test:
        cmd: yarn e2e:utils
        artifact_path: tests/utilsTests

  test_cucumber:
    executor: docker-postgres-executor
    steps:
    - run_e2e_test:
        cmd: yarn cucumber:ci
        artifact_path: reports

  dynamic_security_scan:
    executor: machine-executor
    resource_class: large
    steps:
    - attach_workspace:
        at: .
    - run:
        name: Start up local services
        command: ./bin/prod-style-server
    - run:
        name: Wait for Node.js server to start
        command: ./bin/ping-server 8080
    - run:
        name: Pull OWASP ZAP docker image
        command: docker pull zaproxy/zap-stable:latest
    - run:
        name: Run OWASP ZAP scan for Node.js server
        command: ./bin/run-owasp-scan --target http://server:8080 --full
    - store_artifacts:
        path: reports

  deploy_job:
    executor: docker-executor
    resource_class: large
    parameters:
      target_env:
        type: string
    steps:
    - checkout
    - attach_workspace:
        at: .
    - set_env_vars:
        target_env: << parameters.target_env >>
    - install_cf_tools
    - run:
        name: Build backend assets
        command: yarn build
    - when:
        condition:
          equal: [ << parameters.target_env >>, prod ]
        steps:
        - run:
            name: Create production robots.txt
            command: ./bin/robot-factory
    - run:
        name: Build frontend assets
        command: yarn --cwd frontend run build
    - cf_deploy:
        target_env: << parameters.target_env >>
    - write_envs:
        target_env: << parameters.target_env >>
    - run:
        name: Run database migrations
        command: |
          set -x
          TASK_NAME="$(echo "$CIRCLE_JOB" | tr ' ' '_')-<< parameters.target_env >>-${RANDOM}"
          cf run-task tta-smarthub-${full_env} --command "yarn db:migrate:prod" --name ${TASK_NAME} --wait
          cf logs tta-smarthub-${full_env} --recent | grep ${TASK_NAME}
    - run:
        name: Alert on migration failure
        when: on_fail
        command: |
            msg="DB Migration failed on deploy to << parameters.target_env >>.  ${CIRCLE_BUILD_URL}"
            if [ << parameters.target_env >> == "prod" || << parameters.target_env >> == "staging" ]; then
              ./bin/notify-slack.sh "${msg}" acf-head-start-alerts ${SLACK_BOT_TOKEN}
            fi
    - notify_new_relic:
        target_env: << parameters.target_env >>
    - when:
        condition:
          equal: [ << parameters.target_env >>, prod ]
        steps:
        - notify_slack_deploy:
            slack_bot_token: $SLACK_BOT_TOKEN
            slack_channel: "acf-ohs-ttahub--contractor-customer-team"
            target_env: << parameters.target_env >>

  backup_prod_db:
    executor: docker-executor
    steps:
    - checkout
    - cf_backup:
        target_env: prod
        rds_service_name: ttahub-prod
        s3_service_name: ttahub-db-backups
        backup_prefix: production

  restore_prod_to_temp:
    executor: docker-executor
    steps:
    - checkout
    - cf_restore:
        target_env: prod
        rds_service_name: ttahub-process
        s3_service_name: ttahub-db-backups
        backup_prefix: production

  process_temp_db:
    executor: docker-executor
    steps:
    - checkout
    - create_combined_yarnlock
    - restore_cache:
        keys:
        - v16-yarn-deps-{{ checksum "combined-yarnlock.txt" }}
        - v16-yarn-deps-
    - run: |
        yarn deps
        yarn build
    - cf_process:
        target_env: prod

  backup_temp_db:
    executor: docker-executor
    steps:
    - checkout
    - cf_backup:
        target_env: prod
        rds_service_name: ttahub-process
        s3_service_name: ttahub-db-backups
        backup_prefix: processed

  restore_db_job:
    executor: docker-executor
    parameters:
      target_env:
        type: string
    steps:
    - checkout
    - cf_restore:
        target_env: prod # this is the source of the backup
        rds_service_name: "ttahub-<< parameters.target_env >>"
        s3_service_name: ttahub-db-backups
        backup_prefix: processed
    - cf_migrate:
        app_name: "tta-smarthub-<< parameters.target_env >>"
        target_env: << parameters.target_env >>

  run_cmd:
    # run given command in the target environment
    executor: docker-executor
    parameters:
      command:
        type: string
      target_env:
        type: string
    steps:
    - cf_task:
        the_command: << parameters.command >>
        target_env: "<< parameters.target_env >>"

  # no-op job used for checkpointing others
  checkpoint:
    executor: docker-base
    steps: [ no-op ]

  run_import_job:
    # run the data import / monitoring job in target environment
    executor: docker-executor
    parameters:
      target_env:
        type: string
      slack_channel:
        type: string
        default: acf-head-start-alerts-lower
    steps:
    - checkout
    - cf_task:
        the_command: |
          node ./build/server/src/tools/importSystemCLI.js download 1
          node ./build/server/src/tools/importSystemCLI.js process 1
          yarn createMonitoringGoalsCLI
          node ./build/server/src/tools/queryMonitoringDataCLI.js
          node ./build/server/src/tools/maintainMonitoringDataCLI.js
        target_env: << parameters.target_env >>
        logfile: cmd_log.txt
    - run:
        when: always
        name: Create monitoring updates summary
        command: |
          if grep -o "Recent Monitoring Updates: \[\]" cmd_log.txt; then
            echo "No new monitoring updates ($(date -I))" > monitoring-updates.txt
          else
            results=$(grep -o "Recent Monitoring Updates.*" cmd_log.txt | tail -n 1)
            delim=":"
            json_data=${results#*"$delim"}
            goals=$(echo "$json_data" | jq -jr '.[] | .recipient, " (Region ", .region, ")\n"')
            echo "Monitoring Updates:\n\`\`\`${goals}\`\`\`" > monitoring-updates.txt
          fi
          echo $(grep -o "Error.*" cmd_log.txt | tail -n 1) >> monitoring-updates.txt
          cat monitoring-updates.txt
    - when:
        condition:
          equal: [ << parameters.target_env >>, "prod" ]
        steps:
        - notify_slack:
            message_text_file: monitoring-updates.txt
            slack_channel: << parameters.slack_channel >>

  clear_cache_job:
    executor: docker-executor
    parameters:
      target_env:
        type: string
    steps:
    - checkout
    - install_cf_tools
    - cf_login:
        target_env: << parameters.target_env >>
    - run:
        name: Clear build cache
        command: |
          app_name="tta-smarthub-<< parameters.target_env >>"
          echo "Clearing build cache for ${app_name}"
          app_guid=$(cf app --guid ${app_name})
          cf curl -X POST /v3/apps/${app_guid}/actions/clear_buildpack_cache
          echo "Build cache cleared"

# ----------------- Commands -----------------

commands:

  set_env_vars:
    # set env vars, based on (ci) template in deployment_config
    # these will persist across steps in a job, but not across jobs
    # these values will be available in any subsequent bash env
    parameters:
      target_env:
        type: string
      filename:
        description: "Filename to write env vars to"
        type: string
        default: "env.vars"
      do_export:
        description: "Export env vars to bash env"
        type: boolean
        default: true
    steps:
    - run:
        name: Set env vars (<< parameters.target_env >>)
        command: |
          # $full_env maps to the full env name (dev-blue, dev-green, etc), or same as cfg
          # $cfg_env maps to the primary "level" (dev, staging, prod)
          export full_env=<< parameters.target_env >>
          export cfg_env=${full_env}
          if [[ $full_env == *"dev"* ]]; then cfg_env="dev"; fi
          echo "export full_env=${full_env}" >> "$BASH_ENV"
          echo "export cfg_env=${cfg_env}" >> "$BASH_ENV"
          # convert yml cfg to env style
          ./tools/parse-env-CLI.js ./deployment_config/${cfg_env}_vars.yml ./temp.vars
          # substitute actual values from circle into env.vars file
          circleci env subst < ./temp.vars > env.vars
          # iterate through ci.vars file and export each line,
          while read line; do
            if [ -n "${line}" ] && [ << parameters.do_export >>=='true' ]; then
              echo "export ${line}">>"$BASH_ENV"
            fi
          done < env.vars

  install_cf_tools:
    description: "Install Cloud Foundry CLI"
    steps:
    - run:
        name: Install CF tools
        command: |
          # Install Cloud Foundry CLI
          wget -q -O - https://packages.cloudfoundry.org/debian/cli.cloudfoundry.org.key | sudo apt-key add -
          echo "deb https://packages.cloudfoundry.org/debian stable main" | sudo tee /etc/apt/sources.list.d/cloudfoundry-cli.list
          sudo apt-get update
          sudo apt-get install -y cf8-cli
          # Install plugin needed for connect-to-service
          cf install-plugin -f https://github.com/cloud-gov/cf-service-connect/releases/download/v1.1.4/cf-service-connect_linux_amd64

  run_e2e_test:
    parameters:
      cmd:
        type: string
      artifact_path:
        type: string
    steps:
    - attach_workspace:
        at: .
    - run:
        name: Start backend (8080) & watch logs
        command: |
          export BYPASS_AUTH=true
          export CURRENT_USER_ID=5
          export POSTGRES_USERNAME="postgres"
          export POSTGRES_DB="ttasmarthub"
          yarn start:web
        background: true
    - run:
        name: Start frontend (3000) & watch logs
        command: |
          export POSTGRES_USERNAME="postgres"
          export POSTGRES_DB="ttasmarthub"
          export BYPASS_AUTH=true
          export CURRENT_USER_ID=5
          export TTA_SMART_HUB_URI="http://localhost:3000"
          yarn playwright install
          yarn client
        background: true
    - run:
        name: Start testing server (9999) & watch logs
        command: |
          export POSTGRES_USERNAME="postgres"
          export POSTGRES_DB="ttasmarthub"
          yarn start:testingonly
        background: true
    - run:
        name: Run migrations ci
        command: yarn db:migrate:ci
    - run:
        name: Seed database
        command: yarn db:seed:ci
    - run:
        name: Wait for server to start
        command: |
          ./bin/ping-server 3000 # frontend
          ./bin/ping-server 9999 localhost "/testingonly" # testonly
          #./bin/ping-server 8080 localhost "/health" # backend
          sleep 30s # there is no way to check backend health without auth
    - run:
        name: << parameters.cmd >>
        command: |
          export TTA_SMART_HUB_URI="http://localhost:3000"
          export PLAYWRIGHT_WORKERS=1
          << parameters.cmd >>
    - store_artifacts:
        path: << parameters.artifact_path >>
    - store_test_results:
        path: << parameters.artifact_path >>

  create_combined_yarnlock:
    description: "Concatenate all yarn.json files into single file. File is used as checksum source for part of caching key."
    parameters:
      filename:
        type: string
        default: "combined-yarnlock.txt"
    steps:
    - run:
        name: Combine package-lock.json files to single file
        command: cat yarn.lock frontend/yarn.lock packages/common/yarn.lock > << parameters.filename >>

  sparse_checkout:
    description: "Checkout sparse directories from a specific branch."
    parameters:
      directories:
        type: string
        description: "Comma-separated list of directories to checkout sparsely"
      branch:
        type: string
        description: "Branch to checkout"
    steps:
    - run:
        name: Install Git
        command: |
          sudo apt-get update && sudo apt-get install -y git
    - run:
        name: Clone Repository
        command: |
          git clone --no-checkout --filter=blob:none << pipeline.project.git_url >>.git .
    - run:
        name: Sparse Checkout
        environment:
          DIRECTORIES: "<< parameters.directories >>"
        command: |
          git config core.sparseCheckout true
          echo $DIRECTORIES | tr ',' '\n' | while read dir; do
            echo "$dir" | tee -a .git/info/sparse-checkout
          done

  notify_new_relic:
    description: "Notify new relic of a deploy"
    parameters:
      target_env:
        type: string
    steps:
    - set_env_vars:
        target_env: << parameters.target_env >>
    - run:
        name: Notify New Relic
        command: |
          curl -X POST "https://api.newrelic.com/v2/applications/${new_relic_app_id}/deployments.json" \
          -H "X-Api-Key: $NEW_RELIC_REST_API_KEY" -i \
          -H "Content-Type: application/json" \
          -d \
          "{
            \"deployment\": {
              \"revision\": \"<< pipeline.git.revision >>\",
              \"description\": \"${full_env} Successfully Deployed\"
            }
          }"

  cf_login:
    description: "Login to Cloud Foundry space with service account credentials"
    parameters:
      target_env:
        type: string
    steps:
    - set_env_vars:
        target_env: << parameters.target_env >>
    - run:
        name: Login with service account
        command: |
          cf login -a ${cg_api} \
            -u ${cg_username} \
            -p ${cg_password} \
            -o ${cg_org} \
            -s ${cg_space}

  cf_deploy:
    description: "Login to cloud foundry space with service account credentials and push application using deployment configuration file."
    parameters:
      target_env:
        type: string
    steps:
    - set_env_vars:
        target_env: << parameters.target_env >>
    - run:
        name: Login with service account
        command: |
          cf login -a ${cg_api} \
            -u ${cg_username} \
            -p ${cg_password} \
            -o ${cg_org} \
            -s ${cg_space}
    - run:
        name: Push application
        command: |
          circleci env subst < ./deployment_config/${cfg_env}_vars.yml > app.vars
          cat app.vars
          echo "Deploying app@branch:[$CIRCLE_BRANCH] to [${full_env}]"
          cf push \
            --vars-file app.vars \
            --var BUILD_BRANCH=${CIRCLE_BRANCH} \
            --var BUILD_COMMIT=${CIRCLE_SHA1} \
            --var BUILD_NUMBER=<< pipeline.number >> \
            --var NEW_RELIC_LICENSE_KEY="${NEW_RELIC_LICENSE_KEY}" \
            --var BUILD_TIMESTAMP="$(date +"%Y-%m-%d %H:%M:%S")"

  write_envs:
    parameters:
      target_env:
        type: string
    steps:
    - restore_cache:
        key: 'environment-owners'
    - run:
        name: Write owner into file
        command: |
          mkdir -p environments
          current_env="<< parameters.target_env >>"
          touch msg.txt
          if [ "${current_env}" == 'staging' ] || [ "${current_env}" == 'prod' ]; then
            exit 0;
          fi
          if [ -f ./environments/${current_env} ]; then
            old_owner=$(cat ./environments/${current_env})
            new_owner="${CIRCLE_USERNAME}"
            if [ "${old_owner}" != "${new_owner}" ]; then
              echo "owner changed from ${old_owner}->${new_owner}"
              echo "${new_owner}" > environments/${current_env}
              msg = ""
              cd environments
              for file in *; do
                if [ ! -d ${file} ]; then
                  msg="${file}: $(cat ${file})\n${msg}"
                fi;
              done
              cd ..
              ./bin/notify-slack.sh \
                "Environment owner changed: \`\`\`${msg}\`\`\`" \
                "tm-test"
                ${SLACK_BOT_TOKEN}
            else
              echo "owner not changed: ${old_owner}=${new_owner}"
            fi
          else
            echo "${CIRCLE_USERNAME}" >  environments/${current_env}
          fi
    - save_cache:
        key: 'environment-owners'
        paths:
        - environments

  cf_task:
    description: "Login, run task, send notification"
    parameters:
      the_command:
        description: "Command to run"
        type: string
      target_env:
        description: "Desired env to run cmd in"
        type: string
      logfile:
        type: string
        default: cmd_log.txt
    steps:
    - checkout
    - install_cf_tools
    - set_env_vars:
        target_env: << parameters.target_env >>
    - run:
        name: Login with service account
        command: |
          cf login -a ${cg_api} \
          -u ${cg_username} \
          -p ${cg_password} \
          -o ${cg_org} \
          -s ${cg_space}
    - run:
        name: Set task name
        command: |
          TASK_NAME="$(echo "$CIRCLE_JOB" | tr ' ' '_')-<< parameters.target_env >>-${RANDOM}"
          echo "export TASK_NAME=${TASK_NAME}" >> "$BASH_ENV"
    - run:
        name: "Run @<<parameters.target_env >>: << parameters.the_command >>"
        background: true
        command: |
          cf run-task \
            tta-smarthub-<< parameters.target_env >> \
            --command "<< parameters.the_command >>" \
            --name ${TASK_NAME} \
            -m 2GB \
            -k 2GB

          echo "Watching logs..."
          cf logs tta-smarthub-<< parameters.target_env >> | grep ${TASK_NAME}

    - run:
        name: "Wait for task to complete"
        no_output_timeout: 30m
        command: |
          set +e
          sleep 15
          ./bin/watch-task.js tta-smarthub-<< parameters.target_env >> ${TASK_NAME}
          sleep 30
          cf logs tta-smarthub-<< parameters.target_env >> --recent | grep ${TASK_NAME} | tee << parameters.logfile >>

    - run:
        name: Logout of service account
        command: |
          # Wait for the log monitoring process to terminate
          sleep 5
          # Logout from Cloud Foundry
          cf logout

  cf_backup:
    description: "Backup database to S3"
    parameters:
      target_env: { type: string }
      rds_service_name: { type: string }
      s3_service_name: { type: string }
      backup_prefix: { type: string }
    steps:
    - cf_automation_task:
        task_name: "backup"
        target_env: << parameters.target_env >>
        task_command: "cd /home/vcap/app/db-backup/scripts; bash ./db_backup.sh"
        task_args: '["<< parameters.backup_prefix >>", "<< parameters.rds_service_name >>", "<< parameters.s3_service_name >>"]'
        config: "<< parameters.backup_prefix >>-backup"
        success_message: ':download::database: "<< parameters.backup_prefix >>" backup'

  cf_process:
    description: "Process database from S3"
    parameters:
      target_env: { type: string }
    steps:
    - cf_automation_task:
        target_env: << parameters.target_env >>
        task_name: "process"
        task_command: "cd /home/vcap/app/automation/nodejs/scripts; bash ./run.sh"
        task_args: '["/home/vcap/app/build/server/src/tools/processDataCLI.js"]'
        config: "process"
        success_message: ':database: Restored data processed'
        directory: "./"
        timeout: "3000"

  cf_restore:
    description: "Restore db from S3 to << parameters.target_env >>"
    parameters:
      target_env: { type: string }
      rds_service_name: { type: string }
      s3_service_name: { type: string }
      backup_prefix: { type: string }
    steps:
    - run:
        name: Validate Parameters (<< parameters.target_env >>)
        command: |
          if [ "<< parameters.rds_service_name >>" == "ttahub-prod" ]; then
            echo "Error: rds_service_name cannot be 'ttahub-prod'"
            exit 1
          fi
    - cf_automation_task:
        target_env: << parameters.target_env >>
        task_name: "restore_s3:<< parameters.backup_prefix >>->rds:<< parameters.rds_service_name >>"
        task_command: "cd /home/vcap/app/db-backup/scripts; bash ./db_restore.sh"
        task_args: '["<< parameters.backup_prefix >>", "<< parameters.rds_service_name >>", "<< parameters.s3_service_name >>"]'
        config: "<< parameters.backup_prefix >>-restore"
        success_message: ':database: "<< parameters.backup_prefix >>" restored to "<< parameters.rds_service_name >>"'
        timeout: "1800"
    - run:
        when: on_fail
        command: |
          msg="DB Restore failed to << parameters.rds_service_name >>.  ${CIRCLE_BUILD_URL}"
          ./bin/notify-slack.sh "${msg}" acf-head-start-alerts-lower ${SLACK_BOT_TOKEN}


  cf_retention:
    description: "Delete Backup from S3 based on retention"
    parameters:
      target_env: { type: string }
      s3_service_name: { type: string }
      backup_prefix: { type: string }
    steps:
    - cf_automation_task:
        target_env: << parameters.target_env >>
        task_name: "retention"
        task_command: "cd /home/vcap/app/db-backup/scripts; bash ./db_retention.sh"
        task_args: '["<< parameters.backup_prefix >>", "<< parameters.s3_service_name >>"]'
        config: "<< parameters.backup_prefix >>-backup"
        success_message: ':database: "<< parameters.backup_prefix >>" retention processed'

  cf_migrate:
    description: "Login to Cloud Foundry space, run migration"
    parameters:
      app_name:
        description: "Name of Cloud Foundry cloud.gov application; must match application name specified in manifest"
        type: string
      target_env:
        description: "Desired env to run cmd in"
        type: string
      cg_api:
        description: "Cloud Foundry API endpoint"
        type: string
        default: "https://api.fr.cloud.gov"
    steps:
    - set_env_vars:
        target_env: << parameters.target_env >>
    - run:
        name: Login with service account
        command: |
          cf login -a ${cg_api} \
            -u ${cg_username} \
            -p ${cg_password} \
            -o ${cg_org} \
            -s ${cg_space}
    - run:
        name: "Migrate database: << parameters.app_name >>"
        command: |
          cf run-task << parameters.app_name >> \
            --command "yarn db:migrate:prod" \
            --name "migrate"

  install_automation_deps:
    steps:
    - run:
        name: Install Automation Dependencies
        command: |
          set -e
          set -u
          set -o pipefail
          set -o noglob
          set -o noclobber

          # update
          sudo apt-get update
          # Install uuid-runtime to have access to uuidgen
          # Install pv wget
          sudo apt-get install -y pv uuid-runtime wget coreutils jq apt-utils

          # Install Cloud Foundry CLI
          wget -q -O - https://packages.cloudfoundry.org/debian/cli.cloudfoundry.org.key | sudo apt-key add -
          echo "deb https://packages.cloudfoundry.org/debian stable main" | sudo tee /etc/apt/sources.list.d/cloudfoundry-cli.list
          sudo apt-get update
          sudo apt-get install -y cf8-cli
          # Install plugin needed for connect-to-service
          cf install-plugin -f https://github.com/cloud-gov/cf-service-connect/releases/download/v1.1.4/cf-service-connect_linux_amd64

          # The line you want to ensure exists in the /etc/hosts file
          line="127.0.0.1        localhost"

          # Check if the line already exists
          if ! grep -qF "$line" /etc/hosts; then
              # If the line does not exist, append it
              echo "$line" | sudo tee -a /etc/hosts > /dev/null
              echo "Line added to /etc/hosts"
          else
              echo "Line already exists in /etc/hosts"
          fi

          # cleanup
          sudo rm -rf /var/lib/apt/lists/*

  cf_automation_task:
    description: "Running [<< parameters.task_name >>] from [<< parameters.target_env >>: << parameters.task_args >>]"
    parameters:
      task_name:
        # do not include spaces in the task_name or it will break the status parsing
        description: "Name of the automation task to run"
        type: string
      task_command:
        description: "Command to run for the automation task"
        type: string
      task_args:
        description: "Arguments for the automation task"
        type: string
      target_env:
        description: "Environment to run the task in"
        type: string
      config:
        description: "Config to use for the automation task"
        type: string
      success_message:
        description: "Success message for Slack notification"
        type: string
      timeout:
        description: "Max duration allowed for task"
        type: string
        default: "1800"
      directory:
        description: 'directory to root to push'
        type: string
        default: "./automation"
    steps:
    - install_automation_deps
    - set_env_vars:
        target_env: << parameters.target_env >>
        do_export: false
    - run:
        name: Login with service account
        command: |
          source env.vars
          cf login -a ${cg_api} \
            -u ${cg_username} \
            -p ${cg_password} \
            -o ${cg_org} \
            -s ${cg_space}
    - run:
        name: Watch task logs
        background: true
        command: |
          #!/bin/bash

          CONTROL_FILE="/tmp/stop_tail"
          rm -f $CONTROL_FILE

          # Function to start tailing logs
          start_log_tailing() {
              echo "Starting cf logs for tta-automation..."
              cf logs tta-automation &
              TAIL_PID=$!
          }

          # Start tailing logs for the first time
          start_log_tailing

          # Monitor the cf logs process
          while [ ! -f $CONTROL_FILE ]; do
              # Check if the cf logs process is still running
              if ! kill -0 $TAIL_PID 2>/dev/null; then
                  echo "cf logs command has stopped unexpectedly. Restarting..."
                  start_log_tailing
              fi
              sleep 1
          done

          # Kill the cf logs command
          kill -9 $TAIL_PID
          echo "cf logs command for tta-automation has been terminated."
    - run:
        name: |
          "Running cmd: << parameters.task_name >>
              in << parameters.target_env >>
              args:<< parameters.task_args >>
              cmd: << parameters.task_command >>"
        command: |
          json_data=$(jq -n \
            --arg directory "<< parameters.directory >>" \
            --arg config "<< parameters.config >>" \
            --arg task_name "<< parameters.task_name >>" \
            --arg command "<< parameters.task_command >>" \
            --arg timeout_active_tasks "<< parameters.timeout >>" \
            --arg timeout_ensure_app_stopped "<< parameters.timeout >>" \
            --argjson args '<< parameters.task_args >>' \
            '{
              directory: $directory,
              config: $config,
              task_name: $task_name,
              command: $command,
              timeout_active_tasks: $timeout_active_tasks,
              timeout_ensure_app_stopped: $timeout_ensure_app_stopped,
              args: $args
            }')

          # Set execute permission
          find ./automation -name "*.sh" -exec chmod +x {} \;
          ./automation/ci/scripts/cf_lambda.sh "$json_data"
    - run:
        name: Logout of service account
        command: |
          # Signal the log monitoring to stop
          CONTROL_FILE="/tmp/stop_tail"
          touch $CONTROL_FILE

          # Wait for the log monitoring process to terminate
          sleep 5

          # Logout from Cloud Foundry
          cf logout

  notify_slack:
    description: "Notify Slack @ << parameters.slack_channel >>"
    parameters:
      slack_bot_token:
        description: "Slack bot token"
        type: string
        default: $SLACK_BOT_TOKEN
      slack_channel:
        description: "Slack channel name to post the message to"
        default: "acf-head-start-alerts-lower"
        type: string
      message_text:
        description: "Message text to post to Slack"
        type: string
        default: ""
      message_text_file:
        description: "message text_file.  If provided, this will be used instead of message_text"
        type: string
        default: ""
    steps:
    - run:
        name: Notify Slack
        command: |
          if [[ -n "<< parameters.message_text >>" ]]; then
            MESSAGE="<< parameters.message_text >>"
          else
            MESSAGE=$(cat "<< parameters.message_text_file >>")
          fi

          echo "Sending: ${MESSAGE}"
          # Ensure all parameters are provided
          if [ -z "<< parameters.slack_bot_token >>" ] || [ -z "<< parameters.slack_channel >>" ] || [ -z "$MESSAGE" ]; then
            echo "Missing required parameter. Notification will not be sent."
            exit 0
          fi

          response=$(curl -s -X POST \
            -H "Authorization: Bearer << parameters.slack_bot_token >>" \
            -H 'Content-type: application/json;charset=utf-8' \
            --data "{
              \"channel\": \"<< parameters.slack_channel >>\",
              \"text\": \"$MESSAGE\"
            }" \
            https://slack.com/api/chat.postMessage)
          ok=$(echo $response | jq -r '.ok')
          error=$(echo $response | jq -r '.error')
          if [ "$ok" != "true" ]; then
            echo "Slack notification failed: $error"
            exit 1
          else
            echo "Slack notification sent successfully"
          fi


  notify_slack_deploy:
    parameters:
      slack_bot_token:
        description: "Slack bot token"
        type: string
        default: $SLACK_BOT_TOKEN
      slack_channel:
        description: "Slack channel name to post the message to"
        type: string
      target_env:
        type: string
    steps:
    - checkout
    - set_env_vars:
        target_env: << parameters.target_env >>
    - run:
        name: Generate Slack Message JSON
        command: |
          env_name=<< parameters.target_env >>

          if [ -n "${CIRCLE_PULL_REQUEST}" ]; then
            PR_NUMBER=${CIRCLE_PULL_REQUEST##*/}
          else
            COMMIT_MESSAGE=$(git log -1 --pretty=%B)
            if echo "$COMMIT_MESSAGE" | grep -q "Merge pull request #"; then
              PR_NUMBER=$(echo "$COMMIT_MESSAGE" | grep -oP '(?<=Merge pull request #)\d+')
            else
              echo "No PR number found."
              exit 0
            fi
          fi

          PR_LINK="https://github.com/HHS/Head-Start-TTADP/pull/${PR_NUMBER}"

          PR_DATA=$(curl -s -H "Authorization: token $GITHUB_TOKEN" \
            -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/repos/HHS/Head-Start-TTADP/pulls/${PR_NUMBER}")

          PR_BODY=$(echo "$PR_DATA" | jq -r .body)
          PR_TITLE=$(echo "$PR_DATA" | jq -r .title)

          extract_section() {
            echo "$PR_BODY" | awk -v section="## $1" '
              BEGIN {found=0}
              $0 ~ section {found=1; next}
              /^## / && found {exit}
              found {print}
            ' | head -c 600 | sed 's/^/> /'
          }

          DESC=$(extract_section "Description of change")
          ISSUES=$(extract_section "Issue")

          jq -n \
            --arg channel "<< parameters.slack_channel >>" \
            --arg pr_number "#$PR_NUMBER" \
            --arg pr_link "$PR_LINK" \
            --arg title "$PR_TITLE" \
            --arg desc "$DESC" \
            --arg issues "$ISSUES" \
            --arg env "$env_name" \
            '{
              channel: $channel,
              blocks: [
                { type: "section", text: { type: "mrkdwn", text: ":rocket: Deployment of production PR <\($pr_link)|\($pr_number)> was successful!" } },
                { type: "section", text: { type: "mrkdwn", text: "*Title:*\n\($title)" } },
                { type: "section", text: { type: "mrkdwn", text: "*Description of change:*\n\($desc)" } },
                { type: "section", text: { type: "mrkdwn", text: "*Issues:*\n\($issues)" } },
                { type: "section", text: { type: "mrkdwn", text: ":link: <\($pr_link)|View PR on GitHub>" } }
              ]
            }' > /tmp/message_file.json
    - run:
        name: Post Slack Message
        command: |
          curl -X POST -H "Authorization: Bearer << parameters.slack_bot_token >>" \
            -H 'Content-type: application/json;charset=utf-8' \
            --data "@/tmp/message_file.json" https://slack.com/api/chat.postMessage

  no-op:
    # placeholder command for no-op jobs
    steps:
    - run:
        command: echo "ok"
